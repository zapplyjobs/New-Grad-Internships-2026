name: Update Zapply Jobs

on:
  schedule:
    # Run every hour
    - cron: '*/10 * * * *'
  workflow_dispatch: # Allow manual triggering
  push:
    branches: [ main ]
    paths:
      - '.github/scripts/job-fetcher/**'
      - '.github/scripts/real-career-scraper.js'
      - '.github/scripts/enhanced-discord-bot.js'

# Prevent concurrent runs to avoid queue corruption
concurrency:
  group: job-updates
  cancel-in-progress: false

jobs:
  update-jobs:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        ref: main  # Always pull latest main branch code
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        cache: 'npm'
        cache-dependency-path: |
          package-lock.json
          jobboard/package-lock.json

    - name: Install job fetcher dependencies
      run: npm install axios cheerio

    - name: Install scraper dependencies
      run: |
        npm install puppeteer
        npx puppeteer browsers install chrome

    - name: Install jobboard dependencies
      run: |
        cd jobboard
        npm install --production --no-audit --no-fund
        cd ..

    - name: Create logs directory
      run: mkdir -p .github/logs

    - name: Update job listings
      run: node .github/scripts/job-fetcher/index.js 2>&1 | tee .github/logs/job-fetcher.log
      env:
        PRIMARY_DATA_SOURCE_URL: ${{ secrets.JOB_PROCESSOR_URL }}

    - name: Display job-fetcher logs (always run)
      if: always()
      run: |
        echo "ðŸ“‹ Job Fetcher Output (last 100 lines):"
        tail -100 .github/logs/job-fetcher.log || echo "Log file not found"


    - name: Install bot dependencies
      working-directory: .github/scripts
      run: npm install discord.js@14

    - name: ðŸ” BEFORE bot - Hash posted_jobs.json
      id: before-hash
      run: |
        echo "ðŸ“Š BEFORE BOT EXECUTION:"
        if [ -f ".github/data/posted_jobs.json" ]; then
          echo "File size: $(stat -c'%s' .github/data/posted_jobs.json 2>/dev/null || stat -f'%z' .github/data/posted_jobs.json)"
          BEFORE_HASH=$(sha256sum .github/data/posted_jobs.json 2>/dev/null | cut -d' ' -f1 || shasum -a 256 .github/data/posted_jobs.json | cut -d' ' -f1)
          echo "SHA256: $BEFORE_HASH"
          echo "hash=$BEFORE_HASH" >> $GITHUB_OUTPUT
          echo "Last 3 job IDs:"
          tail -3 .github/data/posted_jobs.json
        else
          echo "âš ï¸  posted_jobs.json does not exist yet"
          echo "hash=NONE" >> $GITHUB_OUTPUT
        fi

    - name: Display job-fetcher summary
      run: |
        echo "ðŸ“Š Job Fetcher Summary:"
        echo "========================"
        if [ -f ".github/logs/job-fetcher.log" ]; then
          # Extract key metrics from log
          echo "âœ… Jobs found:" $(grep -o "Found [0-9]* jobs" .github/logs/job-fetcher.log | tail -1 || echo "0 jobs")
          echo "âœ… After filters:" $(grep -o "After.*filter.*[0-9]* jobs" .github/logs/job-fetcher.log | tail -1 || echo "Unknown")
          echo "ðŸ” Errors:" $(grep -c "Error\|error\|ERROR" .github/logs/job-fetcher.log || echo "0")
          echo "âš ï¸  Warnings:" $(grep -c "Warning\|warning\|WARN" .github/logs/job-fetcher.log || echo "0")
          echo ""
          echo "Last 10 lines of log:"
          tail -10 .github/logs/job-fetcher.log
        else
          echo "âš ï¸  No job-fetcher log found"
        fi

    - name: Export jobs to encrypted JSON (for external job boards)
      run: node .github/scripts/jobs-data-exporter.js
      env:
        LOG_ENCRYPT_PASSWORD: ${{ secrets.LOG_ENCRYPT_PASSWORD }}

    - name: Post new jobs via Enhanced Bot
      run: node .github/scripts/enhanced-discord-bot.js 2>&1 | tee .github/logs/discord-bot.log
      env:
        DISCORD_TOKEN:       ${{ secrets.DISCORD_TOKEN }}
        DISCORD_CHANNEL_ID:  ${{ secrets.DISCORD_CHANNEL_ID }}
        DISCORD_CLIENT_ID:   ${{ secrets.DISCORD_CLIENT_ID }}
        DISCORD_GUILD_ID:    ${{ secrets.DISCORD_GUILD_ID }}
        # Internship category channels (hardcoded - not secrets)
        DISCORD_TECH_CHANNEL_ID: "1429365682948145164"
        DISCORD_AI_CHANNEL_ID: "1446528260627501228"              # NEW: AI/ML internships (Dec 2025)
        DISCORD_DS_CHANNEL_ID: "1446528167362822296"              # NEW: Data Science internships (Dec 2025)
        DISCORD_SALES_CHANNEL_ID: "1429365752145645670"
        DISCORD_MARKETING_CHANNEL_ID: "1429365805090607206"
        DISCORD_FINANCE_CHANNEL_ID: "1429366120854585434"
        DISCORD_HEALTHCARE_CHANNEL_ID: "1429366171840286781"
        DISCORD_PRODUCT_CHANNEL_ID: "1429366236055081131"
        DISCORD_SUPPLY_CHANNEL_ID: "1429366422613786674"
        DISCORD_PM_CHANNEL_ID: "1429366331836207126"
        DISCORD_HR_CHANNEL_ID: "1429366524459745401"
        # Location-specific channels (shared with New-Grad-Jobs)
        DISCORD_REMOTE_USA_CHANNEL_ID: ${{ secrets.DISCORD_REMOTE_USA_CHANNEL_ID }}
        DISCORD_NY_CHANNEL_ID: ${{ secrets.DISCORD_NY_CHANNEL_ID }}
        DISCORD_AUSTIN_CHANNEL_ID: ${{ secrets.DISCORD_AUSTIN_CHANNEL_ID }}
        DISCORD_CHICAGO_CHANNEL_ID: ${{ secrets.DISCORD_CHICAGO_CHANNEL_ID }}
        DISCORD_SEATTLE_CHANNEL_ID: ${{ secrets.DISCORD_SEATTLE_CHANNEL_ID }}
        DISCORD_REDMOND_CHANNEL_ID: ${{ secrets.DISCORD_REDMOND_CHANNEL_ID }}
        DISCORD_MV_CHANNEL_ID: ${{ secrets.DISCORD_MV_CHANNEL_ID }}
        DISCORD_SF_CHANNEL_ID: ${{ secrets.DISCORD_SF_CHANNEL_ID }}
        DISCORD_SUNNYVALE_CHANNEL_ID: ${{ secrets.DISCORD_SUNNYVALE_CHANNEL_ID }}
        DISCORD_SAN_BRUNO_CHANNEL_ID: ${{ secrets.DISCORD_SAN_BRUNO_CHANNEL_ID }}
        DISCORD_BOSTON_CHANNEL_ID: ${{ secrets.DISCORD_BOSTON_CHANNEL_ID }}
        DISCORD_LA_CHANNEL_ID: ${{ secrets.DISCORD_LA_CHANNEL_ID }}

    - name: ðŸ” AFTER bot - Hash posted_jobs.json
      id: after-hash
      run: |
        echo "ðŸ“Š AFTER BOT EXECUTION:"
        if [ -f ".github/data/posted_jobs.json" ]; then
          echo "File size: $(stat -c'%s' .github/data/posted_jobs.json 2>/dev/null || stat -f'%z' .github/data/posted_jobs.json)"
          AFTER_HASH=$(sha256sum .github/data/posted_jobs.json 2>/dev/null | cut -d' ' -f1 || shasum -a 256 .github/data/posted_jobs.json | cut -d' ' -f1)
          echo "SHA256: $AFTER_HASH"
          echo "hash=$AFTER_HASH" >> $GITHUB_OUTPUT
          echo "Last 3 job IDs:"
          tail -3 .github/data/posted_jobs.json
          echo ""
          echo "Git diff check:"
          git diff .github/data/posted_jobs.json | head -20 || echo "No diff detected by git"
        else
          echo "âŒ posted_jobs.json does not exist after bot execution!"
          echo "hash=NONE" >> $GITHUB_OUTPUT
          exit 1
        fi

    - name: ðŸ” Verify database was updated
      run: |
        echo "ðŸ“Š VERIFYING DATABASE UPDATE..."
        echo ""

        BEFORE_HASH="${{ steps.before-hash.outputs.hash }}"
        AFTER_HASH="${{ steps.after-hash.outputs.hash }}"

        echo "Before hash: $BEFORE_HASH"
        echo "After hash:  $AFTER_HASH"
        echo ""

        # First, check for actual posting errors (highest priority)
        if grep -q "âŒ Error posting job" .github/logs/discord-bot.log 2>/dev/null; then
          echo "âŒâŒâŒ CRITICAL ERROR: Jobs failed to post to Discord! âŒâŒâŒ"
          echo ""
          echo "Bot encountered errors while posting jobs."
          echo "Check bot logs above for details."
          exit 1
        fi

        # Second, check if file unchanged (could be expected or error)
        if [ "$BEFORE_HASH" == "$AFTER_HASH" ]; then
          echo "âš ï¸  Database file unchanged - investigating reason..."
          echo ""

          # Check if all jobs were filtered (expected behavior)
          if grep -q "After blacklist filter: 0 jobs" .github/logs/discord-bot.log 2>/dev/null; then
            echo "âœ… SUCCESS: All jobs filtered by blacklist (expected behavior)"
            echo ""
            echo "All new jobs matched blacklist criteria - no jobs posted."
            echo "This is normal and prevents posting unwanted duplicates."
            exit 0
          elif grep -q "No new jobs to post" .github/logs/discord-bot.log 2>/dev/null; then
            echo "âœ… SUCCESS: No new jobs found (expected behavior)"
            echo ""
            echo "All jobs were already posted previously."
            echo "Duplicate detection working correctly."
            exit 0
          elif grep -q "â„¹ï¸ No new jobs to post" .github/logs/discord-bot.log 2>/dev/null; then
            echo "âœ… SUCCESS: No new jobs to post (expected behavior)"
            echo ""
            echo "Either no new jobs found or all filtered as duplicates."
            exit 0
          else
            # File unchanged but we don't know why - this is suspicious!
            echo "âŒâŒâŒ CRITICAL ERROR: posted_jobs.json was NOT modified! âŒâŒâŒ"
            echo ""
            echo "Database unchanged but bot should have posted jobs."
            echo "This could indicate a save failure or other issue."
            echo ""
            echo "Check bot logs above for save errors."
            echo "This workflow will now fail to alert the team."
            exit 1
          fi
        else
          echo "âœ… SUCCESS: Database was updated correctly"
          echo ""
          echo "File hash changed, confirming bot saved posted job IDs."
          echo "Duplicate detection is working properly."
        fi

    - name: Create obfuscated audit log
      if: always()
      run: node .github/scripts/create-audit-log.js

    - name: Check for changes
      id: verify-changed-files
      run: |
        if [ -n "$(git status --porcelain)" ]; then
          echo "changed=true" >> $GITHUB_OUTPUT
          echo "Found changes in README"
        else
          echo "changed=false" >> $GITHUB_OUTPUT
          echo "No changes detected"
        fi
      
    - name: Commit updated job board
      if: steps.verify-changed-files.outputs.changed == 'true'
      run: |
        git config --local user.email "41898282+github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        git add -A
        
        # Get job count from README for commit message
        JOB_COUNT=$(grep -o "Active Positions\*\*: [0-9]*" README.md | grep -o "[0-9]*" || echo "0")
        COMPANY_COUNT=$(grep -o "Companies\*\*: [0-9]*" README.md | grep -o "[0-9]*" || echo "0")
        
        git commit -m "Update jobs - $(date +'%Y-%m-%d')
        
        Found $JOB_COUNT positions from $COMPANY_COUNT companies
        Updated categories, locations, and experience levels
        Next update tomorrow"
        
    - name: ðŸ”„ Pull latest changes
      if: steps.verify-changed-files.outputs.changed == 'true'
      run: |
          echo "ðŸ“¥ Pulling latest changes with rebase (ours strategy) to avoid conflicts..."
           git fetch origin main
           git rebase origin/main --strategy-option=ours || git merge -X ours origin/main --no-edit
           echo "âœ… Pull completed successfully!"


    - name: ðŸš€ Push updated changes with retry logic
      if: steps.verify-changed-files.outputs.changed == 'true'
      run: |
        echo "ðŸš€ Pushing changes with retry logic..."
        for i in 1 2 3; do
          echo "Push attempt $i of 3..."
          if git push origin main; then
            echo "âœ… Successfully pushed changes!"
            break
          else
            echo "âš ï¸ Push failed â€” pulling latest changes before retry..."
            git pull origin main --rebase --autostash || git pull origin main --no-edit
            sleep 5
          fi
        done
        
    - name: Create job summary
      run: |
        echo "## ðŸš€ Zapply Jobs Updated!" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ "${{ steps.verify-changed-files.outputs.changed }}" == "true" ]; then
          # Extract stats from README
          JOB_COUNT=$(grep -o "Active Positions\*\*: [0-9]*" README.md | grep -o "[0-9]*" || echo "0")
          COMPANY_COUNT=$(grep -o "Companies\*\*: [0-9]*" README.md | grep -o "[0-9]*" || echo "0")
          FAANG_COUNT=$(grep -o "FAANG+ Jobs\*\*: [0-9]*" README.md | grep -o "[0-9]*" || echo "0")
          
          echo "âœ… **Successfully updated job board with fresh opportunities**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“Š Today's Haul:" >> $GITHUB_STEP_SUMMARY  
          echo "- ðŸŽ¯ **$JOB_COUNT total positions** from elite tech companies" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ¢ **$COMPANY_COUNT companies** tracked (FAANG, unicorns, startups)" >> $GITHUB_STEP_SUMMARY
          echo "- â­ **$FAANG_COUNT FAANG+ jobs** from top-tier companies" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ” Search Coverage:" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸŒ **Multi-location search**: SF Bay Area, NYC, Seattle, Austin, Remote" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸŽ“ **All experience levels**: Entry-level to Senior positions" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ’¼ **10+ role categories**: SWE, ML/AI, Data, Mobile, DevOps, Product, Design" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ† **Elite companies only**: FAANG, unicorns, top startups, gaming leaders" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸŽ¯ Quality Filters Applied:" >> $GITHUB_STEP_SUMMARY
          echo "- âœ¨ Removed duplicates and spam postings" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ¢ Normalized company names and subsidiaries" >> $GITHUB_STEP_SUMMARY  
          echo "- ðŸ“Š Ranked by company tier (FAANG first)" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ”— Verified direct application links" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**ðŸ”„ Next update**: Tomorrow at 9 AM UTC" >> $GITHUB_STEP_SUMMARY
        else
          echo "â„¹ï¸ **No new opportunities found - job board is current**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "All tracked companies have been checked for new postings." >> $GITHUB_STEP_SUMMARY
          echo "The existing job listings are still fresh and active." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**ðŸ”„ Next check**: Tomorrow at 9 AM UTC" >> $GITHUB_STEP_SUMMARY
        fi
